{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "027201bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üîß FEATURE ENGINEERING\n",
      "======================================================================\n",
      "\n",
      "üìÅ Loading data...\n",
      "   Transactions: 590,540 rows, 394 columns\n",
      "   Identity: 144,233 rows, 41 columns\n",
      "\n",
      "üîó Merging tables...\n",
      "   Merged dataset: 590,540 rows, 434 columns\n",
      "   Transactions with identity info: 140,810 (23.8%)\n",
      "   Transactions without identity info: 449,730 (76.2%)\n",
      "\n",
      "   ‚úÖ Merge successful ‚Äî all transactions preserved\n",
      "\n",
      "üìä Current dataset info:\n",
      "   Shape: (590540, 434)\n",
      "   Memory usage: 2567.1 MB\n",
      "   Target variable (isFraud): 20,663 frauds (3.50%)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# FEATURE ENGINEERING - STEP 1: SETUP AND MERGE DATA\n",
    "# =============================================================================\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"üîß FEATURE ENGINEERING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# LOAD DATA\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\nüìÅ Loading data...\")\n",
    "\n",
    "DATA_PATH = Path(r\"C:\\Users\\aadik\\Desktop\\FraudDetection\\data\")\n",
    "\n",
    "df_transaction = pd.read_csv(DATA_PATH / 'train_transaction.csv')\n",
    "df_identity = pd.read_csv(DATA_PATH / 'train_identity.csv')\n",
    "\n",
    "print(f\"   Transactions: {len(df_transaction):,} rows, {len(df_transaction.columns)} columns\")\n",
    "print(f\"   Identity: {len(df_identity):,} rows, {len(df_identity.columns)} columns\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# MERGE TABLES\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\nüîó Merging tables...\")\n",
    "\n",
    "# Left join: Keep all transactions, add identity info where available\n",
    "df = df_transaction.merge(df_identity, on='TransactionID', how='left')\n",
    "\n",
    "print(f\"   Merged dataset: {len(df):,} rows, {len(df.columns)} columns\")\n",
    "\n",
    "# Verify merge worked correctly\n",
    "transactions_with_identity = df['DeviceType'].notna().sum()\n",
    "print(f\"   Transactions with identity info: {transactions_with_identity:,} ({transactions_with_identity/len(df)*100:.1f}%)\")\n",
    "print(f\"   Transactions without identity info: {len(df) - transactions_with_identity:,} ({(len(df)-transactions_with_identity)/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Verify no rows were lost\n",
    "assert len(df) == len(df_transaction), \"ERROR: Row count changed after merge!\"\n",
    "print(\"\\n   ‚úÖ Merge successful ‚Äî all transactions preserved\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# CHECK CURRENT STATE\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\nüìä Current dataset info:\")\n",
    "print(f\"   Shape: {df.shape}\")\n",
    "print(f\"   Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "print(f\"   Target variable (isFraud): {df['isFraud'].sum():,} frauds ({df['isFraud'].mean()*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e073aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (590540, 434)\n",
      "First 3 columns: ['TransactionID', 'isFraud', 'TransactionDT']\n",
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "print(f\"DataFrame shape: {df.shape}\")\n",
    "print(f\"First 3 columns: {df.columns[:3].tolist()}\")\n",
    "print(\"Test passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88e45c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "‚è∞ STEP 2: TIME-BASED FEATURES\n",
      "======================================================================\n",
      "\n",
      "üìä TransactionDT Analysis:\n",
      "   Minimum value: 86,400 seconds\n",
      "   Maximum value: 15,811,131 seconds\n",
      "   Range: 182.0 days\n",
      "\n",
      "‚úÖ Created time features:\n",
      "   hour: 24 unique values, range [0 - 23]\n",
      "   day_of_week: 7 unique values, range [0 - 6]\n",
      "   is_night: 2 unique values, range [0 - 1]\n",
      "   is_risky_hour: 2 unique values, range [0 - 1]\n",
      "   is_weekend: 2 unique values, range [0 - 1]\n",
      "\n",
      "üîç Validation ‚Äî Do fraud rates match our EDA?\n",
      "   Risky hours (7-9 AM): 9.77% fraud\n",
      "   Normal hours: 3.40% fraud\n",
      "   ‚Üí Risky hours have 2.9x more fraud ‚úì\n",
      "\n",
      "   Night (0-6 AM): 3.99% fraud\n",
      "   Day (7 AM - 11 PM): 3.33% fraud\n",
      "\n",
      "   ‚úÖ Time features created successfully!\n",
      "   New column count: 439\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚è∞ STEP 2: TIME-BASED FEATURES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# UNDERSTANDING TransactionDT\n",
    "# -----------------------------------------------------------------------------\n",
    "# TransactionDT is in seconds from a reference point\n",
    "# We don't know the exact start date, but we can extract relative time features\n",
    "\n",
    "print(\"\\nüìä TransactionDT Analysis:\")\n",
    "print(f\"   Minimum value: {df['TransactionDT'].min():,} seconds\")\n",
    "print(f\"   Maximum value: {df['TransactionDT'].max():,} seconds\")\n",
    "print(f\"   Range: {(df['TransactionDT'].max() - df['TransactionDT'].min()) / 86400:.1f} days\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# CREATE TIME FEATURES\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Hour of day (0-23)\n",
    "# 3600 seconds = 1 hour\n",
    "# We use modulo 24 to wrap around (hour 25 becomes hour 1)\n",
    "df['hour'] = (df['TransactionDT'] // 3600) % 24\n",
    "\n",
    "# Day of week (0-6)\n",
    "# 86400 seconds = 1 day\n",
    "# We use modulo 7 to get day of week\n",
    "df['day_of_week'] = (df['TransactionDT'] // 86400) % 7\n",
    "\n",
    "# Is it nighttime? (midnight to 6 AM)\n",
    "# Based on EDA: late night has different patterns\n",
    "df['is_night'] = (df['hour'] <= 6).astype(int)\n",
    "\n",
    "# Is it a risky hour? (7 AM to 9 AM)\n",
    "# Based on EDA: these hours have highest fraud rate (10%+)\n",
    "df['is_risky_hour'] = ((df['hour'] >= 7) & (df['hour'] <= 9)).astype(int)\n",
    "\n",
    "# Is it weekend? (assuming day 5 and 6 are weekend)\n",
    "# Note: We don't know actual day names, but patterns should still help\n",
    "df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# VERIFY NEW FEATURES\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n‚úÖ Created time features:\")\n",
    "time_features = ['hour', 'day_of_week', 'is_night', 'is_risky_hour', 'is_weekend']\n",
    "\n",
    "for feature in time_features:\n",
    "    unique_count = df[feature].nunique()\n",
    "    print(f\"   {feature}: {unique_count} unique values, range [{df[feature].min()} - {df[feature].max()}]\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# VALIDATE: Check fraud rates match our EDA findings\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\nüîç Validation ‚Äî Do fraud rates match our EDA?\")\n",
    "\n",
    "# Risky hour fraud rate\n",
    "risky_hour_fraud = df[df['is_risky_hour'] == 1]['isFraud'].mean() * 100\n",
    "normal_hour_fraud = df[df['is_risky_hour'] == 0]['isFraud'].mean() * 100\n",
    "print(f\"   Risky hours (7-9 AM): {risky_hour_fraud:.2f}% fraud\")\n",
    "print(f\"   Normal hours: {normal_hour_fraud:.2f}% fraud\")\n",
    "print(f\"   ‚Üí Risky hours have {risky_hour_fraud/normal_hour_fraud:.1f}x more fraud ‚úì\")\n",
    "\n",
    "# Night fraud rate\n",
    "night_fraud = df[df['is_night'] == 1]['isFraud'].mean() * 100\n",
    "day_fraud = df[df['is_night'] == 0]['isFraud'].mean() * 100\n",
    "print(f\"\\n   Night (0-6 AM): {night_fraud:.2f}% fraud\")\n",
    "print(f\"   Day (7 AM - 11 PM): {day_fraud:.2f}% fraud\")\n",
    "\n",
    "print(f\"\\n   ‚úÖ Time features created successfully!\")\n",
    "print(f\"   New column count: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0f0c393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üö© STEP 3: MISSING DATA FLAGS\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Created missing data flags:\n",
      "\n",
      "   Feature                      Missing %   Fraud if 1   Fraud if 0\n",
      "   ---------------------------------------------------------------\n",
      "   addr1_missing                    11.1%       11.78%        2.46%\n",
      "   addr2_missing                    11.1%       11.78%        2.46%\n",
      "   dist1_missing                    59.7%        4.52%        2.00%\n",
      "   dist2_missing                    93.6%        3.06%        9.92%\n",
      "   P_emaildomain_missing            16.0%        2.95%        3.60%\n",
      "   R_emaildomain_missing            76.8%        2.08%        8.18%\n",
      "   has_identity                     23.8%        7.96%        2.10%\n",
      "\n",
      "   New column count: 446\n",
      "   ‚úÖ Missing data flags created successfully!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 3: MISSING DATA FLAGS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üö© STEP 3: MISSING DATA FLAGS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# WHY MISSING DATA FLAGS?\n",
    "# -----------------------------------------------------------------------------\n",
    "# From EDA we learned:\n",
    "#   - Missing addr1/addr2 = 4x more fraud\n",
    "#   - Missing dist1/dist2 = 3x more fraud  \n",
    "#   - Missing email = suspicious\n",
    "# Instead of just filling missing values, we CREATE A FEATURE from it\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# CREATE MISSING FLAGS\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Address missing flags\n",
    "df['addr1_missing'] = df['addr1'].isna().astype(int)\n",
    "df['addr2_missing'] = df['addr2'].isna().astype(int)\n",
    "\n",
    "# Distance missing flags\n",
    "df['dist1_missing'] = df['dist1'].isna().astype(int)\n",
    "df['dist2_missing'] = df['dist2'].isna().astype(int)\n",
    "\n",
    "# Email missing flags\n",
    "df['P_emaildomain_missing'] = df['P_emaildomain'].isna().astype(int)\n",
    "df['R_emaildomain_missing'] = df['R_emaildomain'].isna().astype(int)\n",
    "\n",
    "# Identity info missing (from identity table)\n",
    "df['has_identity'] = df['DeviceType'].notna().astype(int)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# VERIFY AND VALIDATE\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n‚úÖ Created missing data flags:\")\n",
    "\n",
    "missing_features = ['addr1_missing', 'addr2_missing', 'dist1_missing', \n",
    "                    'dist2_missing', 'P_emaildomain_missing', \n",
    "                    'R_emaildomain_missing', 'has_identity']\n",
    "\n",
    "print(f\"\\n   {'Feature':<25} {'Missing %':>12} {'Fraud if 1':>12} {'Fraud if 0':>12}\")\n",
    "print(f\"   {'-'*63}\")\n",
    "\n",
    "for feature in missing_features:\n",
    "    pct_ones = df[feature].mean() * 100\n",
    "    \n",
    "    fraud_when_1 = df[df[feature] == 1]['isFraud'].mean() * 100\n",
    "    fraud_when_0 = df[df[feature] == 0]['isFraud'].mean() * 100\n",
    "    \n",
    "    print(f\"   {feature:<25} {pct_ones:>11.1f}% {fraud_when_1:>11.2f}% {fraud_when_0:>11.2f}%\")\n",
    "\n",
    "print(f\"\\n   New column count: {len(df.columns)}\")\n",
    "print(\"   ‚úÖ Missing data flags created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebdda888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üí∞ STEP 4: TRANSACTION AMOUNT FEATURES\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Created amount features:\n",
      "\n",
      "   amount_log range: [0.22, 10.37]\n",
      "   amount_decimal range: [0.00, 1.00]\n",
      "\n",
      "üîç Round amount analysis:\n",
      "   Round amounts ($X.00): 3.57% fraud (305,013 transactions)\n",
      "   Non-round amounts: 3.43% fraud\n",
      "\n",
      "üîç Fraud rate by amount bin:\n",
      "   tiny        :   3.83% fraud (   204,524 transactions)\n",
      "   small       :   2.92% fraud (   164,095 transactions)\n",
      "   medium      :   3.05% fraud (   128,041 transactions)\n",
      "   large       :   4.42% fraud (    71,001 transactions)\n",
      "   very_large  :   5.31% fraud (    15,612 transactions)\n",
      "   huge        :   2.46% fraud (     7,267 transactions)\n",
      "\n",
      "   New column count: 450\n",
      "   ‚úÖ Amount features created successfully!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 4: TRANSACTION AMOUNT FEATURES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üí∞ STEP 4: TRANSACTION AMOUNT FEATURES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# WHY TRANSFORM AMOUNT?\n",
    "# -----------------------------------------------------------------------------\n",
    "# Raw transaction amounts are heavily skewed:\n",
    "#   - Most transactions are small ($10-$100)\n",
    "#   - Few transactions are large ($1000+)\n",
    "#   - This skew makes it hard for models to learn patterns\n",
    "#\n",
    "# We'll create:\n",
    "#   1. Log-transformed amount (reduces skew)\n",
    "#   2. Amount decimal part (fraudsters often use round numbers)\n",
    "#   3. Amount bins (categories: small, medium, large)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# CREATE AMOUNT FEATURES\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# 1. Log-transformed amount\n",
    "#    log1p = log(1 + x), the +1 prevents log(0) error\n",
    "df['amount_log'] = np.log1p(df['TransactionAmt'])\n",
    "\n",
    "# 2. Decimal part of amount\n",
    "#    Example: $123.45 ‚Üí 0.45\n",
    "#    Fraudsters often use round numbers ($100, $200)\n",
    "df['amount_decimal'] = df['TransactionAmt'] - df['TransactionAmt'].astype(int)\n",
    "\n",
    "# 3. Is round amount? (ends in .00)\n",
    "df['is_round_amount'] = (df['amount_decimal'] == 0).astype(int)\n",
    "\n",
    "# 4. Amount bins (small, medium, large, very large)\n",
    "df['amount_bin'] = pd.cut(\n",
    "    df['TransactionAmt'],\n",
    "    bins=[0, 50, 100, 200, 500, 1000, float('inf')],\n",
    "    labels=['tiny', 'small', 'medium', 'large', 'very_large', 'huge']\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# VERIFY AND VALIDATE\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n‚úÖ Created amount features:\")\n",
    "print(f\"\\n   amount_log range: [{df['amount_log'].min():.2f}, {df['amount_log'].max():.2f}]\")\n",
    "print(f\"   amount_decimal range: [{df['amount_decimal'].min():.2f}, {df['amount_decimal'].max():.2f}]\")\n",
    "\n",
    "# Check if round amounts have different fraud rates\n",
    "round_fraud = df[df['is_round_amount'] == 1]['isFraud'].mean() * 100\n",
    "not_round_fraud = df[df['is_round_amount'] == 0]['isFraud'].mean() * 100\n",
    "print(f\"\\nüîç Round amount analysis:\")\n",
    "print(f\"   Round amounts ($X.00): {round_fraud:.2f}% fraud ({df['is_round_amount'].sum():,} transactions)\")\n",
    "print(f\"   Non-round amounts: {not_round_fraud:.2f}% fraud\")\n",
    "\n",
    "# Check fraud by amount bin\n",
    "print(f\"\\nüîç Fraud rate by amount bin:\")\n",
    "bin_fraud = df.groupby('amount_bin', observed=True)['isFraud'].agg(['mean', 'count'])\n",
    "bin_fraud['mean'] = bin_fraud['mean'] * 100\n",
    "\n",
    "for bin_name, row in bin_fraud.iterrows():\n",
    "    print(f\"   {bin_name:<12}: {row['mean']:>6.2f}% fraud ({int(row['count']):>10,} transactions)\")\n",
    "\n",
    "print(f\"\\n   New column count: {len(df.columns)}\")\n",
    "print(\"   ‚úÖ Amount features created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "503dfcf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üè∑Ô∏è STEP 5: CATEGORICAL ENCODING FEATURES\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Created categorical features:\n",
      "\n",
      "   Feature                 % of Data   Fraud Rate\n",
      "   ----------------------------------------------\n",
      "   is_product_C                11.6%       11.69%\n",
      "   is_product_W                74.5%        2.04%\n",
      "   is_discover                  1.1%        7.73%\n",
      "   is_credit                   25.2%        6.68%\n",
      "   is_debit                    74.5%        2.43%\n",
      "   is_mobile                    9.4%       10.17%\n",
      "\n",
      "   New column count: 461\n",
      "   ‚úÖ Categorical features created successfully!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 5: CATEGORICAL ENCODING FEATURES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üè∑Ô∏è STEP 5: CATEGORICAL ENCODING FEATURES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# WHY ENCODE CATEGORICALS?\n",
    "# -----------------------------------------------------------------------------\n",
    "# Models need numbers, not text like \"visa\" or \"mastercard\"\n",
    "# We'll create:\n",
    "#   1. Binary flags for risky categories (from EDA findings)\n",
    "#   2. Simple label encoding for other categoricals\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# PRODUCT CATEGORY FLAGS (from EDA: Product C = 11.7% fraud)\n",
    "# -----------------------------------------------------------------------------\n",
    "df['is_product_C'] = (df['ProductCD'] == 'C').astype(int)\n",
    "df['is_product_W'] = (df['ProductCD'] == 'W').astype(int)  # Safest product\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# CARD NETWORK FLAGS (from EDA: Discover = 7.7% fraud)\n",
    "# -----------------------------------------------------------------------------\n",
    "df['is_discover'] = (df['card4'] == 'discover').astype(int)\n",
    "df['is_visa'] = (df['card4'] == 'visa').astype(int)\n",
    "df['is_mastercard'] = (df['card4'] == 'mastercard').astype(int)\n",
    "df['is_amex'] = (df['card4'] == 'american express').astype(int)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# CARD TYPE FLAGS (from EDA: Credit = 6.7% fraud)\n",
    "# -----------------------------------------------------------------------------\n",
    "df['is_credit'] = (df['card6'] == 'credit').astype(int)\n",
    "df['is_debit'] = (df['card6'] == 'debit').astype(int)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# DEVICE TYPE FLAGS (from Identity analysis)\n",
    "# -----------------------------------------------------------------------------\n",
    "df['is_mobile'] = (df['DeviceType'] == 'mobile').astype(int)\n",
    "df['is_desktop'] = (df['DeviceType'] == 'desktop').astype(int)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# EMAIL DOMAIN FLAGS (risky domains from EDA)\n",
    "# -----------------------------------------------------------------------------\n",
    "risky_emails = ['gmail.com', 'yahoo.com', 'hotmail.com', 'outlook.com']\n",
    "df['is_risky_email'] = df['P_emaildomain'].isin(risky_emails).astype(int)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# VERIFY AND VALIDATE\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n‚úÖ Created categorical features:\")\n",
    "\n",
    "cat_features = [\n",
    "    ('is_product_C', 'Product C (risky)'),\n",
    "    ('is_product_W', 'Product W (safe)'),\n",
    "    ('is_discover', 'Discover card'),\n",
    "    ('is_credit', 'Credit card'),\n",
    "    ('is_debit', 'Debit card'),\n",
    "    ('is_mobile', 'Mobile device'),\n",
    "]\n",
    "\n",
    "print(f\"\\n   {'Feature':<20} {'% of Data':>12} {'Fraud Rate':>12}\")\n",
    "print(f\"   {'-'*46}\")\n",
    "\n",
    "for feature, description in cat_features:\n",
    "    pct = df[feature].mean() * 100\n",
    "    fraud_rate = df[df[feature] == 1]['isFraud'].mean() * 100\n",
    "    print(f\"   {feature:<20} {pct:>11.1f}% {fraud_rate:>11.2f}%\")\n",
    "\n",
    "print(f\"\\n   New column count: {len(df.columns)}\")\n",
    "print(\"   ‚úÖ Categorical features created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfa3c63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üìã STEP 6: FEATURE SUMMARY & CLEANUP\n",
      "======================================================================\n",
      "\n",
      "‚úÖ NEW FEATURES CREATED:\n",
      "\n",
      "   Time Features:\n",
      "      ‚Ä¢ hour\n",
      "      ‚Ä¢ day_of_week\n",
      "      ‚Ä¢ is_night\n",
      "      ‚Ä¢ is_risky_hour\n",
      "      ‚Ä¢ is_weekend\n",
      "\n",
      "   Missing Flags:\n",
      "      ‚Ä¢ addr1_missing\n",
      "      ‚Ä¢ addr2_missing\n",
      "      ‚Ä¢ dist1_missing\n",
      "      ‚Ä¢ dist2_missing\n",
      "      ‚Ä¢ P_emaildomain_missing\n",
      "      ‚Ä¢ R_emaildomain_missing\n",
      "      ‚Ä¢ has_identity\n",
      "\n",
      "   Amount Features:\n",
      "      ‚Ä¢ amount_log\n",
      "      ‚Ä¢ amount_decimal\n",
      "      ‚Ä¢ is_round_amount\n",
      "      ‚Ä¢ amount_bin\n",
      "\n",
      "   Product Features:\n",
      "      ‚Ä¢ is_product_C\n",
      "      ‚Ä¢ is_product_W\n",
      "\n",
      "   Card Features:\n",
      "      ‚Ä¢ is_discover\n",
      "      ‚Ä¢ is_visa\n",
      "      ‚Ä¢ is_mastercard\n",
      "      ‚Ä¢ is_amex\n",
      "      ‚Ä¢ is_credit\n",
      "      ‚Ä¢ is_debit\n",
      "\n",
      "   Device Features:\n",
      "      ‚Ä¢ is_mobile\n",
      "      ‚Ä¢ is_desktop\n",
      "      ‚Ä¢ is_risky_email\n",
      "\n",
      "   Total new features: 27\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "üîç DATA QUALITY CHECK\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "   Infinite values: 0\n",
      "   Target (isFraud) nulls: 0\n",
      "   Target distribution: {0: 569877, 1: 20663}\n",
      "   Memory usage: 2684.8 MB\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "üèÜ TOP 15 FEATURES BY FRAUD CORRELATION\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "   Feature                         Correlation\n",
      "   --------------------------------------------\n",
      "   V257                                 0.3831\n",
      "   V246                                 0.3669\n",
      "   V244                                 0.3641\n",
      "   V242                                 0.3606\n",
      "   V201                                 0.3280\n",
      "   V200                                 0.3188\n",
      "   V189                                 0.3082\n",
      "   V188                                 0.3036\n",
      "   V258                                 0.2972\n",
      "   V45                                  0.2818\n",
      "   V158                                 0.2781\n",
      "   V156                                 0.2760\n",
      "   V149                                 0.2733\n",
      "   V228                                 0.2689\n",
      "   V44                                  0.2604\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "üíæ SAVING CHECKPOINT\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "   Saved to: C:\\Users\\aadik\\Desktop\\FraudDetection\\data\\df_engineered.pkl\n",
      "   Shape: (590540, 461)\n",
      "\n",
      "   ‚úÖ Feature engineering complete!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 6: FEATURE SUMMARY & FINAL CLEANUP\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìã STEP 6: FEATURE SUMMARY & CLEANUP\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# LIST ALL NEW FEATURES WE CREATED\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "new_features = {\n",
    "    'Time Features': ['hour', 'day_of_week', 'is_night', 'is_risky_hour', 'is_weekend'],\n",
    "    'Missing Flags': ['addr1_missing', 'addr2_missing', 'dist1_missing', 'dist2_missing', \n",
    "                      'P_emaildomain_missing', 'R_emaildomain_missing', 'has_identity'],\n",
    "    'Amount Features': ['amount_log', 'amount_decimal', 'is_round_amount', 'amount_bin'],\n",
    "    'Product Features': ['is_product_C', 'is_product_W'],\n",
    "    'Card Features': ['is_discover', 'is_visa', 'is_mastercard', 'is_amex', 'is_credit', 'is_debit'],\n",
    "    'Device Features': ['is_mobile', 'is_desktop', 'is_risky_email']\n",
    "}\n",
    "\n",
    "print(\"\\n‚úÖ NEW FEATURES CREATED:\")\n",
    "total_new = 0\n",
    "for category, features in new_features.items():\n",
    "    print(f\"\\n   {category}:\")\n",
    "    for f in features:\n",
    "        if f in df.columns:\n",
    "            print(f\"      ‚Ä¢ {f}\")\n",
    "            total_new += 1\n",
    "        else:\n",
    "            print(f\"      ‚Ä¢ {f} (NOT FOUND)\")\n",
    "\n",
    "print(f\"\\n   Total new features: {total_new}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# CHECK FOR ANY ISSUES\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"üîç DATA QUALITY CHECK\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Check for infinite values\n",
    "inf_counts = np.isinf(df.select_dtypes(include=[np.number])).sum().sum()\n",
    "print(f\"\\n   Infinite values: {inf_counts}\")\n",
    "\n",
    "# Check target variable\n",
    "print(f\"   Target (isFraud) nulls: {df['isFraud'].isna().sum()}\")\n",
    "print(f\"   Target distribution: {df['isFraud'].value_counts().to_dict()}\")\n",
    "\n",
    "# Memory usage\n",
    "memory_mb = df.memory_usage(deep=True).sum() / 1024**2\n",
    "print(f\"   Memory usage: {memory_mb:.1f} MB\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# TOP FEATURES BY FRAUD CORRELATION\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"üèÜ TOP 15 FEATURES BY FRAUD CORRELATION\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Get numerical columns only\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Calculate correlation with fraud\n",
    "correlations = []\n",
    "for col in numerical_cols:\n",
    "    if col != 'isFraud' and df[col].notna().sum() > 0:\n",
    "        corr = df[col].corr(df['isFraud'])\n",
    "        if not np.isnan(corr):\n",
    "            correlations.append({'feature': col, 'correlation': abs(corr)})\n",
    "\n",
    "corr_df = pd.DataFrame(correlations).sort_values('correlation', ascending=False).head(15)\n",
    "\n",
    "print(f\"\\n   {'Feature':<30} {'Correlation':>12}\")\n",
    "print(f\"   {'-'*44}\")\n",
    "for _, row in corr_df.iterrows():\n",
    "    print(f\"   {row['feature']:<30} {row['correlation']:>12.4f}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# SAVE CHECKPOINT\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"üíæ SAVING CHECKPOINT\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Save the engineered dataset\n",
    "checkpoint_path = DATA_PATH / 'df_engineered.pkl'\n",
    "df.to_pickle(checkpoint_path)\n",
    "print(f\"\\n   Saved to: {checkpoint_path}\")\n",
    "print(f\"   Shape: {df.shape}\")\n",
    "print(\"\\n   ‚úÖ Feature engineering complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0de10ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üìä OUR ENGINEERED FEATURES ‚Äî CORRELATION WITH FRAUD\n",
      "======================================================================\n",
      "\n",
      "   Feature                         Correlation    Direction\n",
      "   --------------------------------------------------------\n",
      "   is_product_C                        +0.1614     üî¥ +fraud\n",
      "   addr2_missing                       +0.1595     üî¥ +fraud\n",
      "   addr1_missing                       +0.1595     üî¥ +fraud\n",
      "   R_emaildomain_missing               -0.1401     üü¢ -fraud\n",
      "   has_identity                        +0.1359     üî¥ +fraud\n",
      "   is_product_W                        -0.1355     üü¢ -fraud\n",
      "   is_mobile                           +0.1170     üî¥ +fraud\n",
      "   is_credit                           +0.1005     üî¥ +fraud\n",
      "   is_debit                            -0.0998     üü¢ -fraud\n",
      "   dist2_missing                       -0.0911     üü¢ -fraud\n",
      "   is_desktop                          +0.0675     üî¥ +fraud\n",
      "   dist1_missing                       +0.0673     üî¥ +fraud\n",
      "   amount_decimal                      -0.0488     üü¢ -fraud\n",
      "   is_risky_hour                       +0.0419     üî¥ +fraud\n",
      "   is_risky_email                      +0.0353     üî¥ +fraud\n",
      "   is_discover                         +0.0246     üî¥ +fraud\n",
      "   is_night                            +0.0155     üî¥ +fraud\n",
      "   hour                                -0.0131     üü¢ -fraud\n",
      "   P_emaildomain_missing               -0.0129     üü¢ -fraud\n",
      "   day_of_week                         -0.0077     üü¢ -fraud\n",
      "   is_weekend                          -0.0042     üü¢ -fraud\n",
      "   is_amex                             -0.0041     üü¢ -fraud\n",
      "   is_round_amount                     +0.0039     üî¥ +fraud\n",
      "   is_mastercard                       -0.0025     üü¢ -fraud\n",
      "   amount_log                          -0.0018     üü¢ -fraud\n",
      "   is_visa                             -0.0017     üü¢ -fraud\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "üí° INTERPRETATION\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "   Positive correlation (+) = Higher value ‚Üí More fraud\n",
      "   Negative correlation (-) = Higher value ‚Üí Less fraud\n",
      "\n",
      "   üî¥ Strong fraud indicators (use these!):\n",
      "      ‚Ä¢ addr_missing, has_identity, is_product_C, is_credit, is_mobile\n",
      "\n",
      "   üü¢ Strong safety indicators:\n",
      "      ‚Ä¢ is_product_W, is_debit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CHECK OUR ENGINEERED FEATURES' CORRELATIONS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"üìä OUR ENGINEERED FEATURES ‚Äî CORRELATION WITH FRAUD\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "our_features = [\n",
    "    # Time features\n",
    "    'hour', 'day_of_week', 'is_night', 'is_risky_hour', 'is_weekend',\n",
    "    # Missing flags\n",
    "    'addr1_missing', 'addr2_missing', 'dist1_missing', 'dist2_missing',\n",
    "    'P_emaildomain_missing', 'R_emaildomain_missing', 'has_identity',\n",
    "    # Amount features\n",
    "    'amount_log', 'amount_decimal', 'is_round_amount',\n",
    "    # Product features\n",
    "    'is_product_C', 'is_product_W',\n",
    "    # Card features\n",
    "    'is_discover', 'is_visa', 'is_mastercard', 'is_amex', 'is_credit', 'is_debit',\n",
    "    # Device features\n",
    "    'is_mobile', 'is_desktop', 'is_risky_email'\n",
    "]\n",
    "\n",
    "# Calculate correlations for our features\n",
    "our_correlations = []\n",
    "for col in our_features:\n",
    "    if col in df.columns:\n",
    "        corr = df[col].corr(df['isFraud'])\n",
    "        if not np.isnan(corr):\n",
    "            our_correlations.append({'feature': col, 'correlation': corr, 'abs_corr': abs(corr)})\n",
    "\n",
    "our_corr_df = pd.DataFrame(our_correlations).sort_values('abs_corr', ascending=False)\n",
    "\n",
    "print(f\"\\n   {'Feature':<30} {'Correlation':>12} {'Direction':>12}\")\n",
    "print(f\"   {'-'*56}\")\n",
    "for _, row in our_corr_df.iterrows():\n",
    "    direction = \"üî¥ +fraud\" if row['correlation'] > 0 else \"üü¢ -fraud\"\n",
    "    print(f\"   {row['feature']:<30} {row['correlation']:>+12.4f} {direction:>12}\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n\" + \"-\" * 70)\n",
    "print(\"üí° INTERPRETATION\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\"\"\n",
    "   Positive correlation (+) = Higher value ‚Üí More fraud\n",
    "   Negative correlation (-) = Higher value ‚Üí Less fraud\n",
    "\n",
    "   üî¥ Strong fraud indicators (use these!):\n",
    "      ‚Ä¢ addr_missing, has_identity, is_product_C, is_credit, is_mobile\n",
    "\n",
    "   üü¢ Strong safety indicators:\n",
    "      ‚Ä¢ is_product_W, is_debit\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8fe71c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
